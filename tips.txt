# Critical Development Tips

## When Asked to Copy Code "Exactly"

### The Problem
When asked to copy code "exactly like X", there's a tendency to:
1. Think we understand the "essence" of what needs to be copied
2. Use what seems like equivalent alternatives (e.g., different client libraries that serve similar purposes)
3. Miss crucial implementation details that make the original code work

### Real Example: Supabase Client Issue
- Original working code in ProcessFlowEditor used:
  ```typescript
  import { createBrowserClient } from '@supabase/ssr'
  const supabase = createBrowserClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
  )
  ```

- What we incorrectly used instead:
  ```typescript
  import { createClientComponentClient } from '@supabase/auth-helpers-nextjs'
  const supabase = createClientComponentClient()
  ```

- Result: Cookie parsing errors and authentication issues

### The Lesson
1. When asked to copy something EXACTLY, do exactly that:
   - Use the same imports
   - Use the same function calls
   - Use the same client libraries
   - Use the same implementation details
   
2. Don't assume different approaches are equivalent:
   - Different client libraries may handle auth differently
   - Different implementations may have different cookie handling
   - Small differences can cause major issues

3. If something works in one place and not another:
   - First step should be to make them IDENTICAL
   - Only deviate from the working implementation after it's working

### Remember
"Exactly" means EXACTLY. Not "similarly", not "equivalently", not "essentially the same".
If it works somewhere else in the codebase, copy it character by character first, then understand why it works later. 

IMPORTANT FUNCTIONALITY - DO NOT REMOVE

ProcessFlow Node Creation:
------------------------
1. The ProcessFlow editor MUST support both desktop AND mobile node creation:
   - Desktop: Drag and drop from NodeToolbox
   - Mobile: Direct click/tap on node types in NodeToolbox

2. Critical Implementation Details:
   - NodeToolbox components must have BOTH:
     a) onDragStart handlers (for desktop drag-drop)
     b) onClick handlers (for mobile tap-to-create)
   
3. Node Creation Logic:
   - Uses viewport-aware positioning via getViewport()
   - Calculates center position correctly:
     centerX = (-x + window.innerWidth / 2) / zoom
     centerY = (-y + window.innerHeight / 2) / zoom

4. Why This Matters:
   - Mobile users cannot drag-and-drop
   - Click/tap support is essential for mobile accessibility
   - Previous removals of this feature broke mobile functionality

DO NOT REMOVE OR MODIFY THIS DUAL FUNCTIONALITY WITHOUT EXPLICIT APPROVAL.
Keep both drag-and-drop AND click-to-create handlers in NodeToolbox components. 

## Supabase Client Usage in Next.js

### Client Component Setup
When working with Supabase in client components:
1. ALWAYS use the shared client from `@/lib/supabase` by importing `createClient`
2. DO NOT use `createClientComponentClient` from `@supabase/auth-helpers-nextjs`
3. DO NOT create new instances of `createBrowserClient` directly

```typescript
// ✅ CORRECT WAY
import { createClient } from '@/lib/supabase';

export default function MyComponent() {
  const supabase = createClient();
  // ... rest of component
}

// ❌ WRONG WAY - Don't use createClientComponentClient
import { createClientComponentClient } from '@supabase/auth-helpers-nextjs';

// ❌ WRONG WAY - Don't create browser client directly
import { createBrowserClient } from '@supabase/ssr';
```

### Server Component Setup
For server components, use `createServerClient` from `@supabase/ssr`:

```typescript
import { createServerClient } from '@supabase/ssr';
import { cookies } from 'next/headers';

export default async function ServerComponent() {
  const cookieStore = cookies();
  const supabase = createServerClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
    {
      cookies: {
        get(name: string) {
          return cookieStore.get(name)?.value;
        },
      },
    }
  );
  // ... rest of component
}
```

### Common Patterns
1. Server components handle auth and pass user to client components
2. Client components use the shared client for data operations
3. Always filter data by user_id when querying
4. Use RLS policies to enforce data access at the database level

### Troubleshooting
If you're seeing auth issues or empty data:
1. Check you're using the correct client setup
2. Verify user_id is being used in queries
3. Confirm RLS policies are set up correctly
4. Check the browser console for auth-related errors 

KISS (Keep It Simple, Stupid) Principles:

1. Node Linking: When linking to nodes in the process flow, just use the node ID directly in the URL query parameter.
   - DO: `/dashboard/flows?nodeId=${nodeId}`
   - DON'T: Try to track or pass around additional IDs (flowId, etc.) when the node ID is sufficient
   - WHY: The node ID is unique and the system can find the right flow from just the node ID. Adding extra parameters adds complexity without benefit.

Remember: If you find yourself adding extra fields/parameters to track relationships that already exist in the database, stop and think if you're overcomplicating things. 

# Node Linking System - Issues & Prevention Tips

## Issues Encountered

1. Data Structure Mismatch
   - Problem: Mismatch between database structure (nodes stored in JSONB array) and frontend expectations
   - Impact: Links saved but not displayed in UI
   - Root Cause: Foreign key relationships in Supabase return arrays for one-to-many relationships

2. Type Definition Issues
   - Problem: TypeScript interfaces didn't match actual data structure from database
   - Impact: Runtime errors and incorrect data transformation
   - Root Cause: Not accounting for Supabase's data return format

3. Data Transformation Gaps
   - Problem: Missing proper transformation of database response to UI-ready format
   - Impact: Node data not properly extracted from flow's JSONB array
   - Root Cause: Incomplete understanding of data flow from DB to UI

## Prevention Strategies

1. Database Schema Design
   - Document foreign key relationship return formats
   - Add comments in migrations explaining data structures
   - Use database constraints to enforce data integrity
   - Consider adding database views for complex data structures

2. Type Safety
   - Create separate interfaces for DB responses vs UI models
   - Use discriminated unions for different data states
   - Add runtime type checks for critical data transformations
   - Document type transformation requirements

3. Data Flow
   - Implement proper data transformation layers
   - Add logging for development environments
   - Create data validation utilities
   - Write integration tests for data flow

4. Development Process
   - Create end-to-end tests for critical features
   - Add monitoring for runtime errors
   - Document expected data structures
   - Review database query results during development

5. Code Organization
   - Separate data transformation logic
   - Create utility functions for common transformations
   - Add type guards for runtime checks
   - Document complex data relationships

## Best Practices

1. Database
   - Always test foreign key relationship return formats
   - Document JSONB structure requirements
   - Add appropriate indexes for performance
   - Use database constraints for data integrity

2. TypeScript
   - Create separate types for raw DB data
   - Use type guards for runtime safety
   - Document type transformations
   - Add proper error handling

3. Testing
   - Add unit tests for transformations
   - Create integration tests for data flow
   - Test edge cases and error conditions
   - Validate data at each layer

4. Documentation
   - Document data structures
   - Add comments for complex transformations
   - Create examples of expected data formats
   - Maintain up-to-date API documentation

## Quick Reference

```typescript
// DB Response Type
interface DBResponse {
  flow: ProcessFlowWithNodes[];  // Note: Array from foreign key
}

// UI Model Type
interface UIModel {
  flow: {
    id: string;
    title: string;
  }
}

// Type Guard Example
function isValidFlowData(data: unknown): data is ProcessFlowWithNodes {
  return (
    typeof data === 'object' &&
    data !== null &&
    'nodes' in data &&
    Array.isArray((data as any).nodes)
  );
}

// Data Transformation Example
function transformDBToUI(dbData: DBResponse): UIModel {
  const flowData = Array.isArray(dbData.flow) ? dbData.flow[0] : dbData.flow;
  if (!isValidFlowData(flowData)) {
    throw new Error('Invalid flow data structure');
  }
  return {
    flow: {
      id: flowData.id,
      title: flowData.title
    }
  };
}
```

SEQUENCE TIMING TIPS
------------------

1. Timer Source of Truth
   - ALWAYS use timeSpent from ActiveSequenceContext as the source of truth
   - NEVER try to calculate elapsed time manually using startTime
   - NEVER use lastTimeSpent or historical values for current task timing

2. Task Completion Recording
   - When completing a task, use the CURRENT timeSpent value
   - Do NOT use task.data.lastTimeSpent for the current task
   - Only use completionHistory for PREVIOUSLY completed tasks

3. Sequence Completion
   - For the current task: use timeSpent
   - For previous tasks: use their latest completionHistory entry
   - Calculate total time by summing all task times
   - Reset timeSpent to 0 only AFTER saving completion

4. Common Pitfalls
   - Using startTime to calculate elapsed time (use timeSpent instead)
   - Using lastTimeSpent for current task (use timeSpent instead)
   - Using stale completion history for current task
   - Resetting timer before saving completion

5. Testing Timing Changes
   - Always test with multiple tasks
   - Verify times in completion summary
   - Check task history after completion
   - Test pause/resume functionality
   - Verify sequence history shows correct times

6. Debugging Timing Issues
   - Check ActiveSequenceContext timeSpent
   - Verify task completion records
   - Look for manual time calculations
   - Ensure timer reset happens after saving

Remember: timeSpent from ActiveSequenceContext is ALWAYS the source of truth for the current task!

## Handling User Authentication in Database Operations

### Common 401 Error Pattern
One of the most frequent issues in the app is getting 401 (Unauthorized) errors when inserting/updating data, even when the user appears to be logged in. This typically happens because:

1. The table has RLS (Row Level Security) enabled
2. The table requires a user_id field
3. The RLS policy checks if auth.uid() matches user_id
4. The insert/update operation doesn't include the user_id

### Solution Pattern
When working with tables that have user-based RLS:

```typescript
// ✅ CORRECT WAY - Always include user_id
const addItem = async (data: ItemData) => {
  // 1. Get current session
  const { data: sessionData, error: sessionError } = await supabase.auth.getSession();
  if (sessionError) throw sessionError;
  if (!sessionData.session?.user?.id) throw new Error('No authenticated user');

  // 2. Include user_id in the operation
  const { data: result, error } = await supabase
    .from('your_table')
    .insert({ ...data, user_id: sessionData.session.user.id })
    .select()
    .single();

  if (error) throw error;
  return result;
};

// ❌ WRONG WAY - Missing user_id
const addItem = async (data: ItemData) => {
  const { data: result, error } = await supabase
    .from('your_table')
    .insert(data)  // Missing user_id will cause 401
    .select()
    .single();

  if (error) throw error;
  return result;
};
```

### Checklist for New Tables/Features
When adding new tables or features that require user data:

1. Database Setup:
   - Add user_id column (uuid references auth.users(id))
   - Enable RLS on the table
   - Create RLS policies that check auth.uid()
   - Add NOT NULL constraint on user_id
   - Add foreign key with ON DELETE CASCADE

2. Insert Operations:
   - Always get current session first
   - Verify user is authenticated
   - Include user_id in the insert
   - Handle potential auth errors

3. Update/Delete Operations:
   - RLS policies will handle auth check
   - No need to include user_id in where clause
   - Still handle potential auth errors

### Remember
- 401 errors usually mean you forgot to include user_id
- Always check RLS policies when adding new tables
- Get user session before database operations
- Include user_id in ALL insert operations
- Test with both authenticated and unauthenticated states

## Handling Supabase RLS Policy Migrations

### Common Issues with Policy Migrations
When working with Supabase RLS policies in migrations:

1. Policy Already Exists Error (42710)
   - This happens when trying to create a policy that already exists
   - Solution: Always drop existing policies first using `drop policy if exists`
   - Example:
   ```sql
   -- Drop first
   drop policy if exists "Policy name" on table_name;
   
   -- Then create
   create policy "Policy name" on table_name ...
   ```

2. Best Practices for Policy Migrations
   - Create separate migrations for policy changes
   - Always use `if exists` when dropping
   - Keep policies organized by table
   - Document policy relationships in comments
   - Test policy changes in development first

# Type Error Fix: Metric vs LifeGoalMetric
When encountering the error "Module '@/types/goal' has no exported member 'Metric'" during build:
1. Check that you're using the correct type name from types/goal.ts (e.g., LifeGoalMetric instead of Metric)
2. Ensure property names match the type definition's casing:
   - Use snake_case (e.g., current_value) instead of camelCase (e.g., currentValue)
   - This is because our database uses snake_case for column names
3. Common properties to check:
   - current_value (not currentValue)
   - created_at (not createdAt)
   - updated_at (not updatedAt)
   - goal_id (not goalId)

SKILL-TARGET CONNECTIONS:
- Target nodes point TO skill nodes (target is source, skill is target)
- When finding targets for a skill node, look for INCOMING edges where the skill is the target
- When finding skills for a target node, look for OUTGOING edges where the target is the source
- Debug boxes in nodes show the correct edge directions - use them as reference

TARGET NODE DATA STRUCTURE & DISPLAY:
1. Target Data Fields:
   - type: 'number' | 'boolean' - Determines input and display format
   - targetValue: number | boolean - The actual target value
   - metric: string - What is being measured
   - units: string (optional) - Only for number type
   - isCompleted: boolean - Current completion status
   - attempts: Array - History of attempts

2. Details Panel Display:
   - Show ALL target fields, not just the label
   - For number targets: Show "Value: X units"
   - For boolean targets: Show "Value: Yes/No"
   - Always show completion status (●/○) and attempt count (⚡)
   - Group related fields (type/value, what to measure)

3. Common Mistakes to Avoid:
   - Don't just show target ID or label
   - Don't ignore the target type when displaying value
   - Don't forget to show units for number targets
   - Don't skip the completion status or attempts

4. Edge Direction (CRITICAL):
   - Target nodes are the SOURCE
   - Skill nodes are the TARGET
   - Use e.target === node.id to find incoming edges
   - Use e.source to get the target node IDs

# Supabase Relationship Query Issues & Fixes

## The Problem: "Could not find a relationship between X and Y in the schema cache"

### Root Cause
This error occurs when trying to query nested relationships that don't exist in the database schema. The most common cause is misunderstanding the actual relationship structure in the database.

### Real Example: Goal System Data Loading
**Issue Encountered:**
- Error: "Could not find a relationship between 'life_goals' and 'life_goal_sequence_contributions'"
- Attempted query structure:
  ```sql
  life_goals (
    ...,
    sequence_contributions:life_goal_sequence_contributions (...)
  )
  ```

**Actual Database Schema:**
- `life_goals` → `life_goal_metrics` → `life_goal_sequence_contributions`
- `life_goal_sequence_contributions` is related to `life_goal_metrics`, NOT directly to `life_goals`

**Correct Query Structure:**
  ```sql
  life_goals (
    ...,
    metrics:life_goal_metrics (
      ...,
      sequence_contributions:life_goal_sequence_contributions (...)
    )
  )
  ```

### Prevention Strategies

1. **Always Check Database Models First**
   - Look at the actual table definitions in `database/models/`
   - Check the `relationships` array in each model
   - Understand the foreign key structure
   - Don't assume relationships based on naming conventions

2. **Follow the Foreign Key Chain**
   - Start with the base table
   - Follow foreign key references to understand relationships
   - Build nested queries that match the actual schema
   - Use the database models as the source of truth

3. **Common Relationship Patterns**
   - One-to-many: Parent table → Child table (child has parent_id)
   - Many-to-many: Junction table connects two main tables
   - Self-referencing: Table references itself (e.g., categories)

4. **Debugging Steps**
   - Check the exact error message for table names
   - Look up both tables in the database models
   - Verify the relationship exists in the schema
   - Test the relationship with a simple query first

### Best Practices

1. **Query Structure**
   ```sql
   -- ✅ Correct: Follow actual relationships
   parent_table (
     child_table (
       grandchild_table (...)
     )
   )
   
   -- ❌ Wrong: Assume direct relationship
   parent_table (
     grandchild_table (...)  -- This won't work if no direct relationship
   )
   ```

2. **Data Mapping**
   - Map nested data correctly in the frontend
   - Remove duplicate mappings for the same relationship
   - Use type assertions if TypeScript types are complex
   - Handle null/undefined cases with fallbacks

3. **Error Handling**
   - Add null checks for nested properties: `(metric.thresholds || [])`
   - Use optional chaining: `link.process_flows?.title`
   - Provide default values for missing data
   - Log the actual data structure for debugging

### Quick Reference
- **Check models first**: `database/models/table-name.model.ts`
- **Follow foreign keys**: Child tables reference parent tables
- **Nest queries properly**: Match the actual database relationships
- **Handle missing data**: Use null checks and default values
- **Test relationships**: Use simple queries before complex nested ones

### Remember
The database schema is the source of truth. Always verify relationships exist before trying to query them. If you get a "relationship not found" error, check the actual table definitions and foreign key structure.

# CSS HOVER POPUP TRANSLUCENCY ISSUES

## The Problem: Popups Appearing Translucent/Washed Out

### Root Cause
When creating hover popups in React/Tailwind, they often appear translucent or washed out due to:
1. Light background colors (e.g., `bg-blue-400`, `bg-gray-400`) being inherently light
2. CSS conflicts between Tailwind classes and inline styles
3. Opacity classes not being applied correctly
4. Background colors being overridden by other styles

### Solution: Use Inline Styles for Solid Popups

**For Step Popups:**
```jsx
// ✅ CORRECT - Solid dark popup
<div className="absolute top-full left-1/2 transform -translate-x-1/2 mt-2 px-3 py-2 text-white text-xs rounded-lg opacity-0 group-hover:opacity-100 transition-opacity whitespace-nowrap z-50 border border-gray-800 shadow-lg"
     style={{ backgroundColor: '#111' }}>
  <div className="font-medium">{step.title}</div>
  <div className="absolute -top-2 left-1/2 transform -translate-x-1/2 w-0 h-0 border-l-4 border-r-4 border-b-4 border-transparent" 
       style={{ borderBottomColor: '#111' }}></div>
</div>

// ❌ WRONG - Light colors cause translucency
<div className={`absolute top-full ... ${color} text-black ...`}>
```

**For Note Popups:**
```jsx
// ✅ CORRECT - Solid dark popup
<div className="absolute bottom-full left-1/2 transform -translate-x-1/2 mb-3 px-3 py-2 text-white text-sm rounded-lg opacity-0 group-hover:opacity-100 hover:opacity-100 transition-opacity whitespace-nowrap z-50 border border-gray-800 shadow-lg"
     style={{ backgroundColor: '#111' }}>
  <div className="font-medium mb-1">Step {stepIndex + 1}: {step.title}</div>
  <div className="text-gray-200">{note.note}</div>
  <div className="text-gray-400 text-xs mt-1">{formatDuration(noteTime)} • {note.instanceVersion === 0 ? 'Original' : `Instance ${note.instanceVersion}`}</div>
  <div className="absolute top-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-l-4 border-r-4 border-t-4 border-transparent" 
       style={{ borderTopColor: '#111' }}></div>
</div>
```

### Key Points
1. **Use inline styles** for background colors to avoid CSS conflicts
2. **Use very dark colors** (`#111`, `#000`) for solid appearance
3. **Use white text** (`text-white`) on dark backgrounds
4. **Match triangle pointers** with the same inline style color
5. **Only use opacity-0/opacity-100** for hover effects, no other opacity classes
6. **Remove any conflicting background classes** from the className

### Common Mistakes
- Using light Tailwind colors (`bg-blue-400`, `bg-gray-400`) for popup backgrounds
- Mixing Tailwind background classes with inline styles
- Using `currentColor` for triangle pointers when background is inline style
- Forgetting to match triangle pointer color with background color

### Remember
If a popup looks translucent or washed out, it's almost always because the background color is too light. Use inline styles with dark colors (`#111`, `#000`) for completely solid popups.

# CSS REFRESH ISSUES - USE INLINE STYLES ONLY

## The Problem: Elements Become Translucent After Refresh

### Root Cause
After page refresh, CSS classes can be overridden, applied in wrong order, or conflict with other styles, causing elements to become translucent or washed out even when they were solid before.

### Solution: Use ONLY Inline Styles for Critical Elements

**For Timeline Segments:**
```jsx
// ✅ CORRECT - Inline styles only, no Tailwind classes
const colors = [
  '#3B82F6', // blue
  '#10B981', // green
  '#F59E0B', // yellow
  '#EC4899', // pink
  '#8B5CF6', // purple
  '#14B8A6', // teal
]
const color = colors[idx % colors.length]

<div
  className="group absolute top-0 h-full rounded cursor-pointer"
  style={{ 
    left: `${left}%`, 
    width: `${width}%`,
    backgroundColor: color  // Inline style - will NEVER be overridden
  }}
>

// ❌ WRONG - Tailwind classes can be overridden after refresh
<div className={`group absolute top-0 h-full ${color} rounded cursor-pointer`}>
```

**For Note Dots:**
```jsx
// ✅ CORRECT - Inline styles for colors and opacity
<div
  className="group absolute top-0 w-3 h-3 rounded-full border-2 border-white shadow-sm cursor-pointer transition-all"
  style={{ 
    left: `${notePosition}%`,
    transform: 'translateX(-50%) translateY(-5px)',
    backgroundColor: note.instanceVersion === 0 ? '#F59E0B' : '#8B5CF6',
    opacity: isVisible ? 1 : 0.5  // Inline opacity
  }}
>

// ❌ WRONG - Tailwind classes can conflict
<div className={`group absolute top-0 w-3 h-3 rounded-full border-2 border-white shadow-sm cursor-pointer transition-all ${
  note.instanceVersion === 0 ? 'bg-yellow-400' : 'bg-purple-400'
} ${isVisible ? 'opacity-100' : 'opacity-50'}`}>
```

**For All Interactive Elements:**
```jsx
// ✅ CORRECT - Inline styles for everything
<div
  className="absolute top-0 w-2 h-2 rounded-full border-2 border-white shadow-sm"
  style={{
    left: `${getCurrentTimelinePosition()}%`,
    transform: 'translateX(-50%) translateY(-3px)',
    backgroundColor: '#3B82F6'  // Inline style
  }}
/>

<div
  className="absolute -top-6 text-white text-xs px-2 py-0.5 rounded font-mono font-semibold z-30"
  style={{
    left: `${getCurrentTimelinePosition()}%`,
    transform: 'translateX(-50%)',
    backgroundColor: '#3B82F6'  // Inline style
  }}
>
```

### Key Points
1. **Use inline styles for ALL colors** - `backgroundColor`, `color`, `borderColor`
2. **Use inline styles for ALL opacity** - `opacity: 1` instead of `opacity-100`
3. **Remove ALL Tailwind color classes** - `bg-blue-400`, `text-white`, etc.
4. **Keep positioning classes** - `absolute`, `top-0`, `left-1/2`, etc. are fine
5. **Use hex colors** - `#3B82F6` instead of `bg-blue-400`

### When to Use This Pattern
- Timeline segments that must stay solid
- Hover popups that must stay solid
- Interactive elements that must maintain appearance
- Any element that becomes translucent after refresh
- Critical UI elements that users interact with

### Remember
Inline styles have the highest CSS specificity and will NEVER be overridden by external CSS. If something needs to stay solid after refresh, use inline styles for ALL color and opacity properties.

# DATABASE UPSERT ISSUES - ALWAYS CHECK UNIQUE CONSTRAINTS

## The Problem: Duplicate Entries from Upsert Operations

### Root Cause
When using Supabase's `.upsert()` method, if you don't specify the `onConflict` parameter, it defaults to using the primary key for conflict detection. This can cause duplicate entries when the unique constraint is on different columns.

### Real Example: Points History Tables
**Issue Encountered:**
- Multiple entries for the same area/subarea/goal on the same date
- Auto-save creating duplicate history records
- Inflated daily point totals

**Database Schema (from models):**
```typescript
// area_points_history
{
  name: 'area_points_history_unique_day',
  columns: ['area_id', 'date'],
  unique: true
}

// subarea_points_history  
{
  name: 'subarea_points_history_unique_day',
  columns: ['subarea_id', 'date'],
  unique: true
}

// goal_points_history
{
  name: 'goal_points_history_unique_day', 
  columns: ['goal_id', 'date'],
  unique: true
}
```

**Correct Upsert Implementation:**
```typescript
// ✅ CORRECT - Specify onConflict parameter
const { error: historyError } = await supabase
  .from('area_points_history')
  .upsert({
    user_id: user.id,
    area_id: area.id,
    date: dateStr,
    points: area.daily_points,
    target: area.target_points
  }, {
    onConflict: 'area_id,date'  // Match the unique constraint
  });

// ✅ CORRECT - For subareas
const { error: historyError } = await supabase
  .from('subarea_points_history')
  .upsert({
    user_id: user.id,
    area_id: subarea.area_id,
    subarea_id: subarea.id,
    date: dateStr,
    points: subarea.daily_points,
    target: subarea.target_points
  }, {
    onConflict: 'subarea_id,date'  // Match the unique constraint
  });

// ✅ CORRECT - For goals
const { error: historyError } = await supabase
  .from('goal_points_history')
  .upsert({
    user_id: user.id,
    area_id: goal.life_goal_subareas.area_id,
    subarea_id: goal.subarea_id,
    goal_id: goal.id,
    date: dateStr,
    points: goal.daily_points,
    target: goal.target_points
  }, {
    onConflict: 'goal_id,date'  // Match the unique constraint
  });
```

### Prevention Strategies

1. **Always Check Database Models First**
   - Look at the `indexes` array in the model definition
   - Find the unique constraint (usually named `*_unique_day`)
   - Use those exact columns in the `onConflict` parameter
   - Don't assume the primary key is the conflict target

2. **Common Unique Constraint Patterns**
   - Daily records: `(entity_id, date)`
   - User-specific records: `(user_id, entity_id)`
   - Time-based records: `(entity_id, timestamp)`
   - Composite keys: `(parent_id, child_id, date)`

3. **Debugging Upsert Issues**
   - Check for duplicate entries in the database
   - Verify the unique constraint exists and is correct
   - Ensure `onConflict` parameter matches the constraint
   - Test upsert with existing data to verify behavior

### Best Practices

1. **Always Specify onConflict**
   ```typescript
   // ✅ Always include onConflict
   .upsert(data, { onConflict: 'column1,column2' })
   
   // ❌ Don't rely on default behavior
   .upsert(data)
   ```

2. **Match Database Constraints**
   - Use the exact column names from the unique constraint
   - Order matters: `'area_id,date'` not `'date,area_id'`
   - Include all columns in the constraint

3. **Test Upsert Behavior**
   - Test with existing records
   - Verify updates work correctly
   - Check that duplicates are prevented
   - Monitor database for unexpected entries

### Remember
- Always check the database model's unique constraints before using upsert
- The `onConflict` parameter must match the actual unique constraint
- Don't assume the primary key is the conflict target
- Test upsert operations with existing data to verify behavior

# SUPABASE UPSERT ONCONFLICT SPECIFICATION ERRORS

## The Problem: "there is no unique or exclusion constraint matching the ON CONFLICT specification"

### Root Cause
When using Supabase's `.upsert()` method with `onConflict` parameter, the specified columns must exactly match an existing unique constraint in the database. If the constraint doesn't exist or the column names don't match, you'll get error code "42P10".

### Real Example: Points History Save Issue
**Error Encountered:**
```
Error code: "42P10"
Message: "there is no unique or exclusion constraint matching the ON CONFLICT specification"
```

**Common Causes:**
1. Database schema mismatch - columns don't exist in the table
2. Unique constraint was dropped or never created
3. Column names in `onConflict` don't match actual constraint
4. Migration not applied to database

### Solution: Use Insert + Update Pattern Instead

**Instead of problematic upsert:**
```typescript
// ❌ PROBLEMATIC - May fail with constraint errors
const { error } = await supabase
  .from('table_name')
  .upsert({
    column1: value1,
    column2: value2
  }, {
    onConflict: 'column1,column2'  // May not match actual constraint
  });
```

**Use insert + update pattern:**
```typescript
// ✅ RELIABLE - Works regardless of constraint issues
let { error } = await supabase
  .from('table_name')
  .insert({
    column1: value1,
    column2: value2
  });

// If insert fails due to duplicate, try update instead
if (error && error.code === '23505') { // unique_violation
  const { error: updateError } = await supabase
    .from('table_name')
    .update({
      // fields to update
    })
    .eq('column1', value1)
    .eq('column2', value2);
  
  error = updateError;
}
```

### When to Use This Pattern

1. **When you get "42P10" errors** with upsert operations
2. **When database schema is uncertain** or migrations may not be applied
3. **When working with tables** that have complex unique constraints
4. **For critical operations** that must work reliably

### Benefits

1. **More reliable** - doesn't depend on specific constraint names
2. **Easier to debug** - clear error handling for each step
3. **Works with any unique constraint** - doesn't need to know exact constraint name
4. **Graceful fallback** - handles both insert and update cases

### Error Code Reference

- **23505**: Unique constraint violation (expected when record exists)
- **42P10**: Invalid column reference in ON CONFLICT clause
- **42710**: Duplicate policy/constraint (when creating constraints)

### Remember
When upsert operations fail with constraint specification errors, use the insert + update pattern instead. It's more verbose but more reliable and doesn't depend on knowing the exact constraint names.

# CHARACTER XP CALCULATION - ON-THE-FLY VS STORED

## The Problem: Inflated Character Levels

### Root Cause
Character XP and levels are calculated **on-the-fly** from goal points history, not stored in a separate table. When duplicate entries exist in history tables, the XP calculation becomes inflated.

### How Character XP Works
1. **No stored character data**: The `characters` table doesn't exist in the current database
2. **On-the-fly calculation**: `getCharacterProgress()` calculates XP from goal points history every time
3. **Formula**: Total XP = Sum of goal points × 10
4. **Level calculation**: Uses the XP progression formula to determine level

### Real Example: Inflated Level Issue
**Problem**: Character showing level 7 when it should be level 4
**Cause**: Duplicate entries in `goal_points_history` table were inflating the total points
**Solution**: Clean up duplicate entries in history tables
**Result**: Refresh the page → correct level displays immediately

### Key Points
- **Character data is NOT stored** - it's calculated fresh each time
- **History tables are the source of truth** for XP calculation
- **Duplicate entries in history** = inflated XP = wrong character level
- **Page refresh** will show correct values after fixing history data
- **No need for character table migrations** - the calculation is real-time

### Debugging Character Level Issues
1. Check for duplicate entries in history tables
2. Verify `get_user_total_points` function is working correctly
3. Ensure goal points are being counted properly
4. Refresh the page to see updated calculations

### Remember
Character levels are calculated from goal points history, not stored in a separate table. If character levels seem wrong, check the history tables for duplicate entries or incorrect data.

# LOCAL BUILD TESTING - ALWAYS TEST BEFORE PUSHING

## The Problem: Deployment Failures After Push

### Root Cause
Pushing code directly to GitHub without local testing leads to:
1. TypeScript compilation errors discovered only during Vercel build
2. SSR (Server-Side Rendering) errors from browser-only APIs
3. Build failures that block deployment for hours/days
4. Frustrating back-and-forth debugging cycles

### Solution: Always Run Local Build First

**Before pushing to GitHub:**
```bash
# Always run this before pushing
npm run build
```

**What Local Build Catches:**
1. **TypeScript errors** - Compilation issues, missing types, interface mismatches
2. **SSR errors** - `window is not defined`, `localStorage is not defined`
3. **Import errors** - Missing modules, incorrect paths
4. **Build optimization issues** - Bundle size problems, dependency conflicts

### Real Example: 2-Day Deployment Block
**Problem**: Vercel deployment failing for 2 days due to SSR errors
**Root Cause**: `window` and `localStorage` access during static generation
**Solution**: Added SSR safety checks in:
- `useYouTube.tsx` - Check `typeof window !== 'undefined'`
- `fileCache.ts` - Check `typeof localStorage !== 'undefined'`
- `remarkYoutubeEmbed.ts` - Check `typeof window !== 'undefined'`

**Result**: Local build caught all issues, fixed them, deployment succeeded immediately

### Prevention Strategy

1. **Always Test Locally First**
   ```bash
   # Run before every push
   npm run build
   
   # If build fails, fix locally before pushing
   # Only push when build succeeds with exit code 0
   ```

2. **Common SSR Issues to Check**
   - Browser APIs: `window`, `document`, `localStorage`, `sessionStorage`
   - DOM manipulation: `document.createElement`, `document.head`
   - Browser events: `addEventListener`, `removeEventListener`
   - Third-party libraries that access browser APIs

3. **SSR Safety Pattern**
   ```typescript
   // ✅ CORRECT - Check for browser environment
   if (typeof window !== 'undefined') {
     // Browser-only code here
   }
   
   // ✅ CORRECT - Check for localStorage
   if (typeof window !== 'undefined' && typeof localStorage !== 'undefined') {
     localStorage.setItem('key', 'value');
   }
   
   // ❌ WRONG - Direct access without checks
   window.location.reload();
   localStorage.setItem('key', 'value');
   ```

### Benefits of Local Testing

1. **Faster Feedback** - Catch errors in seconds, not hours
2. **Immediate Fixes** - Debug and resolve issues locally
3. **Confident Deployments** - Know code will deploy successfully
4. **Reduced Frustration** - No more 2-day deployment blocks
5. **Better Development Flow** - Fix → Test → Push → Deploy

### Remember
- **Always run `npm run build` before pushing**
- **Fix all errors locally first**
- **Only push when build succeeds**
- **SSR safety checks prevent most deployment issues**
- **Local testing saves hours of deployment debugging**

This simple habit will make the entire deployment process much smoother and less painful.

# INFINITE LOOP PREVENTION - MEMOIZE SUPABASE CLIENT

## The Problem: Infinite API Calls and Database Timeouts

### Root Cause
When using Supabase client in React hooks, creating a new client instance on every render causes infinite loops:

1. **Client recreation**: `const supabase = createClient()` creates new instance each render
2. **useCallback dependency**: `fetchAreas` depends on `supabase` instance
3. **useEffect trigger**: `useEffect` depends on `fetchAreas` function
4. **Infinite loop**: New client → new function → useEffect runs → new client → repeat

### Real Example: Goal System Performance Issue
**Problem**: 
- Repeated 500 errors: "canceling statement due to statement timeout"
- Console flooded with "Fetching areas..." logs
- Database overwhelmed with identical requests
- UI becomes unresponsive

**Root Cause**: Infinite loop in `useGoalSystem` hook
```typescript
// ❌ PROBLEMATIC - Creates new client every render
export function useGoalSystem() {
  const supabase = createClient(); // New instance each render
  const fetchAreas = useCallback(async () => {
    // ... fetch logic
  }, [supabase]); // Depends on changing client instance
  
  useEffect(() => {
    fetchAreas(); // Runs on every render due to changing dependency
  }, [fetchAreas]); // fetchAreas changes every render
}
```

**Solution**: Memoize the Supabase client
```typescript
// ✅ CORRECT - Memoized client instance
export function useGoalSystem() {
  const [supabase] = useState(() => createClient()); // Stable instance
  const fetchAreas = useCallback(async () => {
    // ... fetch logic
  }, [supabase]); // Now depends on stable instance
  
  // Remove problematic useEffect that caused infinite loop
  // Only call fetchAreas when auth state changes
}
```

### Prevention Strategies

1. **Always Memoize Supabase Client**
   ```typescript
   // ✅ CORRECT - Use useState to memoize
   const [supabase] = useState(() => createClient());
   
   // ❌ WRONG - Creates new instance each render
   const supabase = createClient();
   ```

2. **Avoid Unnecessary useEffect Dependencies**
   ```typescript
   // ✅ CORRECT - Only depend on stable references
   useEffect(() => {
     // Only run when auth state changes
   }, [supabase]); // Stable client instance
   
   // ❌ WRONG - Depends on function that changes every render
   useEffect(() => {
     fetchAreas();
   }, [fetchAreas]); // fetchAreas changes every render
   ```

3. **Use useCallback Wisely**
   ```typescript
   // ✅ CORRECT - Stable dependencies
   const fetchAreas = useCallback(async () => {
     // ... fetch logic
   }, [supabase]); // Only stable client instance
   
   // ❌ WRONG - Unstable dependencies
   const fetchAreas = useCallback(async () => {
     // ... fetch logic
   }, [supabase, someState]); // someState changes cause function recreation
   ```

### Common Patterns That Cause Loops

1. **Client Recreation**
   ```typescript
   // ❌ PROBLEMATIC
   const supabase = createClient(); // New instance each render
   ```

2. **Function Recreation**
   ```typescript
   // ❌ PROBLEMATIC
   const fetchData = useCallback(() => {
     // ...
   }, [supabase, otherState]); // otherState changes cause recreation
   ```

3. **useEffect with Changing Dependencies**
   ```typescript
   // ❌ PROBLEMATIC
   useEffect(() => {
     fetchData();
   }, [fetchData]); // fetchData changes every render
   ```

### Debugging Infinite Loops

1. **Check Console Logs**
   - Look for repeated function calls
   - Check for "Fetching..." or similar logs
   - Monitor for database timeout errors

2. **Check useCallback Dependencies**
   - Ensure dependencies are stable
   - Remove unnecessary dependencies
   - Use primitive values when possible

3. **Check useEffect Dependencies**
   - Avoid depending on functions that change
   - Only depend on stable references
   - Consider using useRef for mutable values

### Best Practices

1. **Memoize External Clients**
   ```typescript
   const [supabase] = useState(() => createClient());
   const [apiClient] = useState(() => new ApiClient());
   ```

2. **Stable Function References**
   ```typescript
   const fetchData = useCallback(async () => {
     // ... logic
   }, [stableDependency]); // Only stable dependencies
   ```

3. **Minimal useEffect Dependencies**
   ```typescript
   useEffect(() => {
     // Only run when necessary
   }, [stableDependency]); // Avoid function dependencies
   ```

### Remember
- **Always memoize Supabase client** with `useState(() => createClient())`
- **Avoid depending on functions** in useEffect dependencies
- **Use stable references** for useCallback dependencies
- **Monitor console logs** for repeated function calls
- **Fix infinite loops immediately** - they can overwhelm the database

This pattern prevents the most common cause of performance issues and database timeouts in React applications using Supabase.

# VIRTUAL CHARACTER SYSTEM - NO CHARACTERS TABLE

## The Problem: Assuming Character Data is Stored

### Root Cause
The Guardian Angel app uses a **virtual character system** where character data is calculated on-the-fly from points history, not stored in a separate `characters` table. This can cause confusion when implementing character-related features.

### How the Virtual Character System Works
1. **No stored character data**: There is no `characters` table in the database
2. **On-the-fly calculation**: Character XP and levels are calculated from goal points history
3. **Formula**: Total XP = Sum of goal points × 10
4. **Level calculation**: Uses XP progression formula to determine level
5. **Virtual character ID**: Uses `character-${user.id}` pattern for trait storage

### Real Example: Traits System Implementation
**Problem**: Trying to reference non-existent `characters` table in migrations
**Root Cause**: Assumed character data was stored in a table
**Solution**: Use `user_id` directly and virtual character IDs for traits

### Implementation Pattern for Character Features

```typescript
// ✅ CORRECT - Use virtual character system
const loadTraits = async () => {
  // Use virtual character ID based on user_id
  const virtualCharacterId = `character-${user.id}`;
  
  const { data: traitsData } = await supabase
    .from('character_traits')
    .select('*')
    .eq('character_id', virtualCharacterId);
};

// ❌ WRONG - Try to access non-existent characters table
const { data: character } = await supabase
  .from('characters')  // This table doesn't exist!
  .select('id')
  .eq('user_id', user.id);
```

### Database Schema for Character Features
```sql
-- ✅ CORRECT - Use user_id directly
CREATE TABLE trait_sessions (
    id uuid PRIMARY KEY,
    user_id uuid REFERENCES auth.users(id),  -- Direct user reference
    task_id uuid,
    -- ... other fields
);

-- ✅ CORRECT - Use virtual character_id for traits
CREATE TABLE character_traits (
    id uuid PRIMARY KEY,
    character_id text NOT NULL,  -- Virtual ID like 'character-123'
    name text NOT NULL,
    value integer NOT NULL,
    -- ... other fields
);
```

### Character XP Calculation
```typescript
// Character XP is calculated from goal points history
export async function getCharacterProgress(userId: string) {
  const totalPoints = await calculateTotalPoints(userId);
  const totalXP = totalPoints * XP_PER_POINT;
  
  // Calculate level from XP
  let level = 1;
  let remainingXP = totalXP;
  
  while (remainingXP >= calculateRequiredXP(level)) {
    remainingXP -= calculateRequiredXP(level);
    level++;
  }
  
  return { level, xp: remainingXP, requiredXP: calculateRequiredXP(level) };
}
```

### Common Mistakes to Avoid
1. **Don't create a `characters` table** - character data is virtual
2. **Don't assume character data is stored** - it's calculated on-the-fly
3. **Don't reference non-existent `characters` table** in migrations
4. **Don't try to store character XP/level** - it's derived from points history
5. **Do use virtual character IDs** for trait storage (`character-${user.id}`)

### Remember
- **Character data is virtual** - calculated from points history, not stored
- **Use `user_id` directly** for session tracking
- **Use virtual character IDs** (`character-${user.id}`) for traits
- **Character XP = Sum of goal points × 10**
- **No `characters` table exists** - don't reference it in migrations

# ALWAYS CHECK DATABASE MODELS BEFORE IMPLEMENTING FEATURES

## The Problem: Field Name Assumptions Lead to Broken Features

### Root Cause
When implementing features that interact with database data, making assumptions about field names without checking the actual database schema leads to:
1. **Data mapping failures** - Fields not being copied correctly
2. **Missing functionality** - Features that don't work because data isn't passed through
3. **Type mismatches** - Expected fields don't exist in the actual data structure
4. **Wasted debugging time** - Hours spent fixing issues that could have been prevented

### Real Example: Practice Visualization Tooltip Issue
**Problem**: Tooltip showing basic info only, missing date and notes
**Root Cause**: Assumed field names without checking database models
**Data Structure Mismatch**:
- **Assumed**: `date` and `notes` fields
- **Actual**: `completedAt` (timestamp) and `note` (singular) fields

**Result**: 2+ hours of debugging for a simple field mapping issue

### The Solution: ALWAYS Check Database Models First

**Before implementing ANY feature that uses database data:**

1. **Check the database models** in `database/models/` directory
2. **Look at existing interfaces** in the codebase that use the same data
3. **Examine the actual data structure** with console logging if needed
4. **Follow established patterns** for data transformation

### Prevention Strategy

```typescript
// ✅ CORRECT APPROACH
// 1. First, check database/models/table-name.model.ts
// 2. Look at existing interfaces that use this data
// 3. Then implement with correct field names

interface ActualDataStructure {
  completedAt: number;  // From database model
  note?: string;        // From database model (singular!)
  timeSpent: number;
}

// Map to UI-friendly structure
const mappedData = rawData.map(record => ({
  date: record.completedAt ? new Date(record.completedAt).toISOString() : undefined,
  notes: record.note,  // note -> notes for UI
  timeSpent: record.timeSpent
}));

// ❌ WRONG APPROACH
// Assume field names without checking
interface AssumedDataStructure {
  date?: string;        // Wrong - actual field is completedAt (number)
  notes?: string;       // Wrong - actual field is note (singular)
  timeSpent: number;
}
```

### Established Memory Pattern
This aligns with the existing memory: **"ALWAYS check the database models in database/models/ first before making any code changes or database migrations. The models are the source of truth for the database schema."**

### Common Field Name Patterns to Watch For
- **Timestamps**: Often `completedAt`, `createdAt`, `updatedAt` (not `date`)
- **Notes**: Often `note` (singular) not `notes` (plural)
- **IDs**: Often `entity_id` not `entityId` (snake_case vs camelCase)
- **Status**: Check exact enum values in the model
- **Relationships**: Check foreign key names and relationship structures

### Debugging Steps When Data is Missing
1. **Log the raw data** at the source to see actual field names
2. **Check the database model** for the table being queried
3. **Look for existing interfaces** that use the same data
4. **Fix the mapping** to use correct field names
5. **Remove debug logging** after confirming fix

### Remember
- **Database models are the source of truth** - not assumptions
- **Field names matter** - `note` vs `notes`, `completedAt` vs `date`
- **Check existing code** - other parts of the app likely use the same data
- **Log raw data** - when in doubt, console.log the actual structure
- **Follow established patterns** - don't reinvent data transformation

This simple step of checking database models first prevents the majority of data-related bugs and saves hours of debugging time.

# DIALOG SCROLLING ISSUES - ALWAYS ADD OVERFLOW HANDLING

## The Problem: Fixed Height Dialogs with Long Content

### Root Cause
When creating dialogs with long content (questionnaires, forms, trait classification), the dialog becomes fixed height and users cannot scroll to see all content. This is a recurring UX problem that blocks user interaction.

### Real Example: Trait Classification Dialog
**Problem**: User can't scroll to see top or bottom of trait classification questionnaire
**Root Cause**: Dialog content exceeds viewport height with no overflow handling
**Impact**: Users cannot complete the questionnaire, feature becomes unusable

### Solution: Always Add Overflow Handling to Dialogs

**For Long Content Dialogs:**
```tsx
// ✅ CORRECT - Add max-height and overflow
<DialogContent className="sm:max-w-[500px] max-h-[80vh] overflow-y-auto">
  <DialogHeader>
    <DialogTitle>Long Form Title</DialogTitle>
  </DialogHeader>
  
  {/* Long content here */}
  <div className="space-y-6">
    {/* Multiple sections that might exceed viewport */}
  </div>
</DialogContent>

// ❌ WRONG - No overflow handling
<DialogContent className="sm:max-w-[500px]">
  {/* Long content that gets cut off */}
</DialogContent>
```

**Alternative: Break Into Steps**
```tsx
// ✅ GOOD ALTERNATIVE - Multi-step approach
{step === 1 && (
  <div className="space-y-4">
    {/* First few questions */}
  </div>
)}
{step === 2 && (
  <div className="space-y-4">
    {/* Remaining questions */}
  </div>
)}
```

### Prevention Strategies

1. **Always Test Dialog Height**
   - Test on different screen sizes (mobile, tablet, desktop)
   - Test with longest possible content
   - Verify scrolling works on all devices
   - Check that buttons at bottom are accessible

2. **Use Consistent Dialog Patterns**
   ```tsx
   // Standard pattern for all dialogs with potential long content
   <DialogContent className="sm:max-w-[500px] max-h-[80vh] overflow-y-auto">
     <DialogHeader className="flex-shrink-0">
       {/* Header content - always visible */}
     </DialogHeader>
     
     <div className="flex-1 overflow-y-auto py-4">
       {/* Scrollable content area */}
     </div>
     
     <div className="flex-shrink-0 border-t pt-4">
       {/* Footer buttons - always visible */}
     </div>
   </DialogContent>
   ```

3. **Consider Mobile First**
   - Mobile screens have limited height
   - Portrait orientation is most restrictive
   - Test on actual mobile devices when possible
   - Use `max-h-[90vh]` for mobile-friendly dialogs

### Common Dialog Types That Need This

1. **Forms with many fields** (task creation, user profiles)
2. **Questionnaires** (trait classification, surveys)
3. **Lists with many items** (selection dialogs, search results)
4. **Content viewers** (help text, documentation)
5. **Multi-section dialogs** (settings, preferences)

### Quick Fix for Existing Dialogs

```tsx
// Find dialogs with this pattern:
<DialogContent className="sm:max-w-[500px]">

// Replace with:
<DialogContent className="sm:max-w-[500px] max-h-[80vh] overflow-y-auto">
```

### Remember
- **Always add overflow handling** to dialogs with dynamic or long content
- **Test on mobile devices** - they have the most restrictive height
- **Use `max-h-[80vh] overflow-y-auto`** as the standard pattern
- **Keep headers and footers fixed** - only make content area scrollable
- **This is a recurring issue** - check every new dialog for scrolling

This pattern ensures dialogs remain usable regardless of content length or screen size.

# SUPABASE JSONB SYNTAX ERRORS - AVOID JSONB IN MIGRATIONS

## The Problem: "syntax error at or near "->" in SQL Migrations

### Root Cause
When using JSONB fields in Supabase SQL migrations, the `->` operator and JSONB-specific syntax can cause parsing errors. This is a recurring issue that blocks database migrations.

### Real Example: Token Shop Migration
**Error**: `ERROR: 42601: syntax error at or near "->" LINE 12: -> ^`
**Root Cause**: JSONB field with complex JSON structure in INSERT statements
**Impact**: Migration fails, sophisticated features can't be deployed

### Solution: Use TEXT Instead of JSONB for Complex Data

**Instead of JSONB:**
```sql
-- ❌ PROBLEMATIC - JSONB with complex JSON
CREATE TABLE shop_items (
  effects jsonb NOT NULL DEFAULT '[]'::jsonb,
  -- ...
);

INSERT INTO shop_items (effects) VALUES (
  '[{"type":"permission","value":"music_time","duration":30}]'
);
```

**Use TEXT:**
```sql
-- ✅ RELIABLE - TEXT field for JSON data
CREATE TABLE shop_items (
  effects text NOT NULL DEFAULT '[]',
  -- ...
);

INSERT INTO shop_items (effects) VALUES (
  '[{"type":"permission","value":"music_time","duration":30}]'
);
```

### Prevention Strategies

1. **Always Use TEXT for JSON Data in Migrations**
   ```sql
   -- ✅ CORRECT - TEXT field
   effects text NOT NULL DEFAULT '[]',
   
   -- ❌ AVOID - JSONB in migrations
   effects jsonb NOT NULL DEFAULT '[]'::jsonb,
   ```

2. **Avoid JSONB-Specific Functions**
   ```sql
   -- ✅ CORRECT - String concatenation
   VALUES (p_user_id, v_item.id, p_qty, v_needed, 
           '{"item_id": "' || p_item_id || '", "effects": ' || v_item.effects || '}');
   
   -- ❌ AVOID - jsonb_build_object
   VALUES (p_user_id, v_item.id, p_qty, v_needed, 
           jsonb_build_object('item_id', p_item_id, 'effects', v_item.effects));
   ```

3. **Parse JSON in Application Code**
   ```typescript
   // ✅ CORRECT - Parse JSON in TypeScript
   const effects = JSON.parse(item.effects || '[]');
   
   // ✅ CORRECT - Stringify for storage
   const effectsJson = JSON.stringify(effects);
   ```

### When to Use JSONB vs TEXT

**Use TEXT when:**
- Creating SQL migrations
- Storing JSON data that will be parsed in application code
- Avoiding migration syntax errors
- Working with complex JSON structures

**Use JSONB when:**
- Querying JSON data directly in SQL
- Using JSON operators (`->`, `->>`, `@>`)
- Performance is critical for JSON queries
- Database-level JSON validation is needed

### Common JSONB Migration Issues

1. **INSERT Statement Errors**
   - Complex JSON in INSERT values
   - JSONB operators in migration scripts
   - Nested JSON structures

2. **Function Parameter Errors**
   - JSONB parameters in stored functions
   - JSONB return types in functions
   - JSONB operators in function bodies

3. **Constraint Errors**
   - JSONB check constraints
   - JSONB default values
   - JSONB index creation

### Best Practices

1. **Start with TEXT**
   ```sql
   -- Always start with TEXT for JSON data
   effects text NOT NULL DEFAULT '[]',
   ```

2. **Parse in Application**
   ```typescript
   // Handle JSON parsing in TypeScript
   const effects = JSON.parse(item.effects || '[]');
   ```

3. **Convert to JSONB Later (if needed)**
   ```sql
   -- Only convert to JSONB after migration is stable
   ALTER TABLE shop_items ALTER COLUMN effects TYPE jsonb USING effects::jsonb;
   ```

### Remember
- **Always use TEXT for JSON data in migrations** - avoids syntax errors
- **Parse JSON in application code** - more reliable than SQL parsing
- **Avoid JSONB-specific operators** in migration scripts
- **This is a recurring issue** - check every migration with JSON data
- **Convert to JSONB later** if database-level JSON operations are needed

This pattern prevents the most common cause of SQL migration failures when working with JSON data.

# SESSIONTIMER STUCK RUNNING - MANUAL DATABASE CLEANUP

## The Problem: Timer Continues Running After Session Should Be Stopped

### Root Cause
When SessionTimer gets stuck showing a running timer that won't stop with pause/complete buttons, it's usually because:
1. Multiple active sessions exist in the database for the same task
2. Browser state is out of sync with database state
3. Session records have `t_end = NULL` when they should be completed

### Real Example: "Review Slide Deck 5" Timer Issue
**Problem**: Timer showing 190+ minutes and continuing to run despite clicking stop/pause
**Root Cause**: Multiple active sessions in `trait_sessions` table with `t_end = NULL`
**Impact**: Timer unusable, cannot track actual work time

### Diagnosis Steps

1. **Check for Active Sessions**
   ```sql
   SELECT id, task_id, t_start, t_end, duration_min, paused_at 
   FROM trait_sessions 
   WHERE t_end IS NULL 
   ORDER BY t_start DESC;
   ```

2. **Find Sessions for Specific Task**
   ```sql
   SELECT ts.id, ts.task_id, t.title, ts.t_start, ts.t_end, ts.duration_min, ts.paused_at 
   FROM trait_sessions ts
   JOIN tasks t ON ts.task_id = t.id
   WHERE t.title LIKE '%Task Name%' 
   AND ts.t_end IS NULL
   ORDER BY ts.t_start DESC;
   ```

### Manual Fix: Stop Active Sessions

**For Each Active Session:**
```sql
-- Replace 'session-id-here' with actual session ID
-- Replace 62 with desired duration in minutes
UPDATE trait_sessions 
SET t_end = NOW(), 
    duration_min = 62, 
    paused_at = NULL 
WHERE id = 'session-id-here';
```

**Alternative: Stop by Task and Timestamp**
```sql
-- If session ID doesn't work, use task_id and timestamp
UPDATE trait_sessions 
SET t_end = NOW(), 
    duration_min = 62, 
    paused_at = NULL 
WHERE task_id = 'task-id-here' 
AND t_start = '2025-08-17 12:12:50.019+00'
AND t_end IS NULL;
```

### Verification

**Check Session Was Updated:**
```sql
SELECT id, task_id, t_start, t_end, duration_min, paused_at 
FROM trait_sessions 
WHERE id = 'session-id-here';
```

**Verify No More Active Sessions:**
```sql
SELECT id, task_id, t_start, t_end, duration_min, paused_at 
FROM trait_sessions 
WHERE t_end IS NULL 
ORDER BY t_start DESC;
```

### After Database Fix

1. **Refresh the browser page** - Timer should now show correct duration
2. **Verify timer is stopped** - Should not continue incrementing
3. **Test new session** - Start/pause/stop should work normally

### Prevention

1. **Auto-stop on task completion** - SessionTimer now watches for task status changes
2. **Proper pause handling** - Pause sets both `paused_at` and stops timer
3. **Session cleanup** - Active sessions are ended when tasks are completed

### Common Patterns

**Multiple Sessions Same Task:**
- Often happens when browser crashes or user closes tab during active session
- Each browser session can create its own active session record
- Solution: Stop all active sessions for the task

**Timer Shows Huge Time:**
- Timer calculates from `t_start` to current time
- If session started hours/days ago and never stopped, timer shows accumulated time
- Solution: Set appropriate `duration_min` when stopping session

### Remember
- **Always check database first** when timer behavior is unexpected
- **Multiple active sessions** are the most common cause of stuck timers
- **Refresh browser after database fix** to sync UI with database state
- **Set realistic duration** when manually stopping sessions (don't use calculated time)
- **This is a manual fix** - use only when SessionTimer UI controls don't work

This pattern provides a reliable way to fix stuck timers when the UI controls fail to stop active sessions.

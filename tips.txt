# Critical Development Tips

## When Asked to Copy Code "Exactly"

### The Problem
When asked to copy code "exactly like X", there's a tendency to:
1. Think we understand the "essence" of what needs to be copied
2. Use what seems like equivalent alternatives (e.g., different client libraries that serve similar purposes)
3. Miss crucial implementation details that make the original code work

### Real Example: Supabase Client Issue
- Original working code in ProcessFlowEditor used:
  ```typescript
  import { createBrowserClient } from '@supabase/ssr'
  const supabase = createBrowserClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
  )
  ```

- What we incorrectly used instead:
  ```typescript
  import { createClientComponentClient } from '@supabase/auth-helpers-nextjs'
  const supabase = createClientComponentClient()
  ```

- Result: Cookie parsing errors and authentication issues

### The Lesson
1. When asked to copy something EXACTLY, do exactly that:
   - Use the same imports
   - Use the same function calls
   - Use the same client libraries
   - Use the same implementation details
   
2. Don't assume different approaches are equivalent:
   - Different client libraries may handle auth differently
   - Different implementations may have different cookie handling
   - Small differences can cause major issues

3. If something works in one place and not another:
   - First step should be to make them IDENTICAL
   - Only deviate from the working implementation after it's working

### Remember
"Exactly" means EXACTLY. Not "similarly", not "equivalently", not "essentially the same".
If it works somewhere else in the codebase, copy it character by character first, then understand why it works later. 

IMPORTANT FUNCTIONALITY - DO NOT REMOVE

ProcessFlow Node Creation:
------------------------
1. The ProcessFlow editor MUST support both desktop AND mobile node creation:
   - Desktop: Drag and drop from NodeToolbox
   - Mobile: Direct click/tap on node types in NodeToolbox

2. Critical Implementation Details:
   - NodeToolbox components must have BOTH:
     a) onDragStart handlers (for desktop drag-drop)
     b) onClick handlers (for mobile tap-to-create)
   
3. Node Creation Logic:
   - Uses viewport-aware positioning via getViewport()
   - Calculates center position correctly:
     centerX = (-x + window.innerWidth / 2) / zoom
     centerY = (-y + window.innerHeight / 2) / zoom

4. Why This Matters:
   - Mobile users cannot drag-and-drop
   - Click/tap support is essential for mobile accessibility
   - Previous removals of this feature broke mobile functionality

DO NOT REMOVE OR MODIFY THIS DUAL FUNCTIONALITY WITHOUT EXPLICIT APPROVAL.
Keep both drag-and-drop AND click-to-create handlers in NodeToolbox components. 

## Supabase Client Usage in Next.js

### Client Component Setup
When working with Supabase in client components:
1. ALWAYS use the shared client from `@/lib/supabase` by importing `createClient`
2. DO NOT use `createClientComponentClient` from `@supabase/auth-helpers-nextjs`
3. DO NOT create new instances of `createBrowserClient` directly

```typescript
// ✅ CORRECT WAY
import { createClient } from '@/lib/supabase';

export default function MyComponent() {
  const supabase = createClient();
  // ... rest of component
}

// ❌ WRONG WAY - Don't use createClientComponentClient
import { createClientComponentClient } from '@supabase/auth-helpers-nextjs';

// ❌ WRONG WAY - Don't create browser client directly
import { createBrowserClient } from '@supabase/ssr';
```

### Server Component Setup
For server components, use `createServerClient` from `@supabase/ssr`:

```typescript
import { createServerClient } from '@supabase/ssr';
import { cookies } from 'next/headers';

export default async function ServerComponent() {
  const cookieStore = cookies();
  const supabase = createServerClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
    {
      cookies: {
        get(name: string) {
          return cookieStore.get(name)?.value;
        },
      },
    }
  );
  // ... rest of component
}
```

### Common Patterns
1. Server components handle auth and pass user to client components
2. Client components use the shared client for data operations
3. Always filter data by user_id when querying
4. Use RLS policies to enforce data access at the database level

### Troubleshooting
If you're seeing auth issues or empty data:
1. Check you're using the correct client setup
2. Verify user_id is being used in queries
3. Confirm RLS policies are set up correctly
4. Check the browser console for auth-related errors 

KISS (Keep It Simple, Stupid) Principles:

1. Node Linking: When linking to nodes in the process flow, just use the node ID directly in the URL query parameter.
   - DO: `/dashboard/flows?nodeId=${nodeId}`
   - DON'T: Try to track or pass around additional IDs (flowId, etc.) when the node ID is sufficient
   - WHY: The node ID is unique and the system can find the right flow from just the node ID. Adding extra parameters adds complexity without benefit.

Remember: If you find yourself adding extra fields/parameters to track relationships that already exist in the database, stop and think if you're overcomplicating things. 

# Node Linking System - Issues & Prevention Tips

## Issues Encountered

1. Data Structure Mismatch
   - Problem: Mismatch between database structure (nodes stored in JSONB array) and frontend expectations
   - Impact: Links saved but not displayed in UI
   - Root Cause: Foreign key relationships in Supabase return arrays for one-to-many relationships

2. Type Definition Issues
   - Problem: TypeScript interfaces didn't match actual data structure from database
   - Impact: Runtime errors and incorrect data transformation
   - Root Cause: Not accounting for Supabase's data return format

3. Data Transformation Gaps
   - Problem: Missing proper transformation of database response to UI-ready format
   - Impact: Node data not properly extracted from flow's JSONB array
   - Root Cause: Incomplete understanding of data flow from DB to UI

## Prevention Strategies

1. Database Schema Design
   - Document foreign key relationship return formats
   - Add comments in migrations explaining data structures
   - Use database constraints to enforce data integrity
   - Consider adding database views for complex data structures

2. Type Safety
   - Create separate interfaces for DB responses vs UI models
   - Use discriminated unions for different data states
   - Add runtime type checks for critical data transformations
   - Document type transformation requirements

3. Data Flow
   - Implement proper data transformation layers
   - Add logging for development environments
   - Create data validation utilities
   - Write integration tests for data flow

4. Development Process
   - Create end-to-end tests for critical features
   - Add monitoring for runtime errors
   - Document expected data structures
   - Review database query results during development

5. Code Organization
   - Separate data transformation logic
   - Create utility functions for common transformations
   - Add type guards for runtime checks
   - Document complex data relationships

## Best Practices

1. Database
   - Always test foreign key relationship return formats
   - Document JSONB structure requirements
   - Add appropriate indexes for performance
   - Use database constraints for data integrity

2. TypeScript
   - Create separate types for raw DB data
   - Use type guards for runtime safety
   - Document type transformations
   - Add proper error handling

3. Testing
   - Add unit tests for transformations
   - Create integration tests for data flow
   - Test edge cases and error conditions
   - Validate data at each layer

4. Documentation
   - Document data structures
   - Add comments for complex transformations
   - Create examples of expected data formats
   - Maintain up-to-date API documentation

## Quick Reference

```typescript
// DB Response Type
interface DBResponse {
  flow: ProcessFlowWithNodes[];  // Note: Array from foreign key
}

// UI Model Type
interface UIModel {
  flow: {
    id: string;
    title: string;
  }
}

// Type Guard Example
function isValidFlowData(data: unknown): data is ProcessFlowWithNodes {
  return (
    typeof data === 'object' &&
    data !== null &&
    'nodes' in data &&
    Array.isArray((data as any).nodes)
  );
}

// Data Transformation Example
function transformDBToUI(dbData: DBResponse): UIModel {
  const flowData = Array.isArray(dbData.flow) ? dbData.flow[0] : dbData.flow;
  if (!isValidFlowData(flowData)) {
    throw new Error('Invalid flow data structure');
  }
  return {
    flow: {
      id: flowData.id,
      title: flowData.title
    }
  };
}
```

SEQUENCE TIMING TIPS
------------------

1. Timer Source of Truth
   - ALWAYS use timeSpent from ActiveSequenceContext as the source of truth
   - NEVER try to calculate elapsed time manually using startTime
   - NEVER use lastTimeSpent or historical values for current task timing

2. Task Completion Recording
   - When completing a task, use the CURRENT timeSpent value
   - Do NOT use task.data.lastTimeSpent for the current task
   - Only use completionHistory for PREVIOUSLY completed tasks

3. Sequence Completion
   - For the current task: use timeSpent
   - For previous tasks: use their latest completionHistory entry
   - Calculate total time by summing all task times
   - Reset timeSpent to 0 only AFTER saving completion

4. Common Pitfalls
   - Using startTime to calculate elapsed time (use timeSpent instead)
   - Using lastTimeSpent for current task (use timeSpent instead)
   - Using stale completion history for current task
   - Resetting timer before saving completion

5. Testing Timing Changes
   - Always test with multiple tasks
   - Verify times in completion summary
   - Check task history after completion
   - Test pause/resume functionality
   - Verify sequence history shows correct times

6. Debugging Timing Issues
   - Check ActiveSequenceContext timeSpent
   - Verify task completion records
   - Look for manual time calculations
   - Ensure timer reset happens after saving

Remember: timeSpent from ActiveSequenceContext is ALWAYS the source of truth for the current task!

## Handling User Authentication in Database Operations

### Common 401 Error Pattern
One of the most frequent issues in the app is getting 401 (Unauthorized) errors when inserting/updating data, even when the user appears to be logged in. This typically happens because:

1. The table has RLS (Row Level Security) enabled
2. The table requires a user_id field
3. The RLS policy checks if auth.uid() matches user_id
4. The insert/update operation doesn't include the user_id

### Solution Pattern
When working with tables that have user-based RLS:

```typescript
// ✅ CORRECT WAY - Always include user_id
const addItem = async (data: ItemData) => {
  // 1. Get current session
  const { data: sessionData, error: sessionError } = await supabase.auth.getSession();
  if (sessionError) throw sessionError;
  if (!sessionData.session?.user?.id) throw new Error('No authenticated user');

  // 2. Include user_id in the operation
  const { data: result, error } = await supabase
    .from('your_table')
    .insert({ ...data, user_id: sessionData.session.user.id })
    .select()
    .single();

  if (error) throw error;
  return result;
};

// ❌ WRONG WAY - Missing user_id
const addItem = async (data: ItemData) => {
  const { data: result, error } = await supabase
    .from('your_table')
    .insert(data)  // Missing user_id will cause 401
    .select()
    .single();

  if (error) throw error;
  return result;
};
```

### Checklist for New Tables/Features
When adding new tables or features that require user data:

1. Database Setup:
   - Add user_id column (uuid references auth.users(id))
   - Enable RLS on the table
   - Create RLS policies that check auth.uid()
   - Add NOT NULL constraint on user_id
   - Add foreign key with ON DELETE CASCADE

2. Insert Operations:
   - Always get current session first
   - Verify user is authenticated
   - Include user_id in the insert
   - Handle potential auth errors

3. Update/Delete Operations:
   - RLS policies will handle auth check
   - No need to include user_id in where clause
   - Still handle potential auth errors

### Remember
- 401 errors usually mean you forgot to include user_id
- Always check RLS policies when adding new tables
- Get user session before database operations
- Include user_id in ALL insert operations
- Test with both authenticated and unauthenticated states

## Handling Supabase RLS Policy Migrations

### Common Issues with Policy Migrations
When working with Supabase RLS policies in migrations:

1. Policy Already Exists Error (42710)
   - This happens when trying to create a policy that already exists
   - Solution: Always drop existing policies first using `drop policy if exists`
   - Example:
   ```sql
   -- Drop first
   drop policy if exists "Policy name" on table_name;
   
   -- Then create
   create policy "Policy name" on table_name ...
   ```

2. Best Practices for Policy Migrations
   - Create separate migrations for policy changes
   - Always use `if exists` when dropping
   - Keep policies organized by table
   - Document policy relationships in comments
   - Test policy changes in development first

# Type Error Fix: Metric vs LifeGoalMetric
When encountering the error "Module '@/types/goal' has no exported member 'Metric'" during build:
1. Check that you're using the correct type name from types/goal.ts (e.g., LifeGoalMetric instead of Metric)
2. Ensure property names match the type definition's casing:
   - Use snake_case (e.g., current_value) instead of camelCase (e.g., currentValue)
   - This is because our database uses snake_case for column names
3. Common properties to check:
   - current_value (not currentValue)
   - created_at (not createdAt)
   - updated_at (not updatedAt)
   - goal_id (not goalId)

SKILL-TARGET CONNECTIONS:
- Target nodes point TO skill nodes (target is source, skill is target)
- When finding targets for a skill node, look for INCOMING edges where the skill is the target
- When finding skills for a target node, look for OUTGOING edges where the target is the source
- Debug boxes in nodes show the correct edge directions - use them as reference

TARGET NODE DATA STRUCTURE & DISPLAY:
1. Target Data Fields:
   - type: 'number' | 'boolean' - Determines input and display format
   - targetValue: number | boolean - The actual target value
   - metric: string - What is being measured
   - units: string (optional) - Only for number type
   - isCompleted: boolean - Current completion status
   - attempts: Array - History of attempts

2. Details Panel Display:
   - Show ALL target fields, not just the label
   - For number targets: Show "Value: X units"
   - For boolean targets: Show "Value: Yes/No"
   - Always show completion status (●/○) and attempt count (⚡)
   - Group related fields (type/value, what to measure)

3. Common Mistakes to Avoid:
   - Don't just show target ID or label
   - Don't ignore the target type when displaying value
   - Don't forget to show units for number targets
   - Don't skip the completion status or attempts

4. Edge Direction (CRITICAL):
   - Target nodes are the SOURCE
   - Skill nodes are the TARGET
   - Use e.target === node.id to find incoming edges
   - Use e.source to get the target node IDs

# Supabase Relationship Query Issues & Fixes

## The Problem: "Could not find a relationship between X and Y in the schema cache"

### Root Cause
This error occurs when trying to query nested relationships that don't exist in the database schema. The most common cause is misunderstanding the actual relationship structure in the database.

### Real Example: Goal System Data Loading
**Issue Encountered:**
- Error: "Could not find a relationship between 'life_goals' and 'life_goal_sequence_contributions'"
- Attempted query structure:
  ```sql
  life_goals (
    ...,
    sequence_contributions:life_goal_sequence_contributions (...)
  )
  ```

**Actual Database Schema:**
- `life_goals` → `life_goal_metrics` → `life_goal_sequence_contributions`
- `life_goal_sequence_contributions` is related to `life_goal_metrics`, NOT directly to `life_goals`

**Correct Query Structure:**
  ```sql
  life_goals (
    ...,
    metrics:life_goal_metrics (
      ...,
      sequence_contributions:life_goal_sequence_contributions (...)
    )
  )
  ```

### Prevention Strategies

1. **Always Check Database Models First**
   - Look at the actual table definitions in `database/models/`
   - Check the `relationships` array in each model
   - Understand the foreign key structure
   - Don't assume relationships based on naming conventions

2. **Follow the Foreign Key Chain**
   - Start with the base table
   - Follow foreign key references to understand relationships
   - Build nested queries that match the actual schema
   - Use the database models as the source of truth

3. **Common Relationship Patterns**
   - One-to-many: Parent table → Child table (child has parent_id)
   - Many-to-many: Junction table connects two main tables
   - Self-referencing: Table references itself (e.g., categories)

4. **Debugging Steps**
   - Check the exact error message for table names
   - Look up both tables in the database models
   - Verify the relationship exists in the schema
   - Test the relationship with a simple query first

### Best Practices

1. **Query Structure**
   ```sql
   -- ✅ Correct: Follow actual relationships
   parent_table (
     child_table (
       grandchild_table (...)
     )
   )
   
   -- ❌ Wrong: Assume direct relationship
   parent_table (
     grandchild_table (...)  -- This won't work if no direct relationship
   )
   ```

2. **Data Mapping**
   - Map nested data correctly in the frontend
   - Remove duplicate mappings for the same relationship
   - Use type assertions if TypeScript types are complex
   - Handle null/undefined cases with fallbacks

3. **Error Handling**
   - Add null checks for nested properties: `(metric.thresholds || [])`
   - Use optional chaining: `link.process_flows?.title`
   - Provide default values for missing data
   - Log the actual data structure for debugging

### Quick Reference
- **Check models first**: `database/models/table-name.model.ts`
- **Follow foreign keys**: Child tables reference parent tables
- **Nest queries properly**: Match the actual database relationships
- **Handle missing data**: Use null checks and default values
- **Test relationships**: Use simple queries before complex nested ones

### Remember
The database schema is the source of truth. Always verify relationships exist before trying to query them. If you get a "relationship not found" error, check the actual table definitions and foreign key structure.

# CSS HOVER POPUP TRANSLUCENCY ISSUES

## The Problem: Popups Appearing Translucent/Washed Out

### Root Cause
When creating hover popups in React/Tailwind, they often appear translucent or washed out due to:
1. Light background colors (e.g., `bg-blue-400`, `bg-gray-400`) being inherently light
2. CSS conflicts between Tailwind classes and inline styles
3. Opacity classes not being applied correctly
4. Background colors being overridden by other styles

### Solution: Use Inline Styles for Solid Popups

**For Step Popups:**
```jsx
// ✅ CORRECT - Solid dark popup
<div className="absolute top-full left-1/2 transform -translate-x-1/2 mt-2 px-3 py-2 text-white text-xs rounded-lg opacity-0 group-hover:opacity-100 transition-opacity whitespace-nowrap z-50 border border-gray-800 shadow-lg"
     style={{ backgroundColor: '#111' }}>
  <div className="font-medium">{step.title}</div>
  <div className="absolute -top-2 left-1/2 transform -translate-x-1/2 w-0 h-0 border-l-4 border-r-4 border-b-4 border-transparent" 
       style={{ borderBottomColor: '#111' }}></div>
</div>

// ❌ WRONG - Light colors cause translucency
<div className={`absolute top-full ... ${color} text-black ...`}>
```

**For Note Popups:**
```jsx
// ✅ CORRECT - Solid dark popup
<div className="absolute bottom-full left-1/2 transform -translate-x-1/2 mb-3 px-3 py-2 text-white text-sm rounded-lg opacity-0 group-hover:opacity-100 hover:opacity-100 transition-opacity whitespace-nowrap z-50 border border-gray-800 shadow-lg"
     style={{ backgroundColor: '#111' }}>
  <div className="font-medium mb-1">Step {stepIndex + 1}: {step.title}</div>
  <div className="text-gray-200">{note.note}</div>
  <div className="text-gray-400 text-xs mt-1">{formatDuration(noteTime)} • {note.instanceVersion === 0 ? 'Original' : `Instance ${note.instanceVersion}`}</div>
  <div className="absolute top-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-l-4 border-r-4 border-t-4 border-transparent" 
       style={{ borderTopColor: '#111' }}></div>
</div>
```

### Key Points
1. **Use inline styles** for background colors to avoid CSS conflicts
2. **Use very dark colors** (`#111`, `#000`) for solid appearance
3. **Use white text** (`text-white`) on dark backgrounds
4. **Match triangle pointers** with the same inline style color
5. **Only use opacity-0/opacity-100** for hover effects, no other opacity classes
6. **Remove any conflicting background classes** from the className

### Common Mistakes
- Using light Tailwind colors (`bg-blue-400`, `bg-gray-400`) for popup backgrounds
- Mixing Tailwind background classes with inline styles
- Using `currentColor` for triangle pointers when background is inline style
- Forgetting to match triangle pointer color with background color

### Remember
If a popup looks translucent or washed out, it's almost always because the background color is too light. Use inline styles with dark colors (`#111`, `#000`) for completely solid popups.

# CSS REFRESH ISSUES - USE INLINE STYLES ONLY

## The Problem: Elements Become Translucent After Refresh

### Root Cause
After page refresh, CSS classes can be overridden, applied in wrong order, or conflict with other styles, causing elements to become translucent or washed out even when they were solid before.

### Solution: Use ONLY Inline Styles for Critical Elements

**For Timeline Segments:**
```jsx
// ✅ CORRECT - Inline styles only, no Tailwind classes
const colors = [
  '#3B82F6', // blue
  '#10B981', // green
  '#F59E0B', // yellow
  '#EC4899', // pink
  '#8B5CF6', // purple
  '#14B8A6', // teal
]
const color = colors[idx % colors.length]

<div
  className="group absolute top-0 h-full rounded cursor-pointer"
  style={{ 
    left: `${left}%`, 
    width: `${width}%`,
    backgroundColor: color  // Inline style - will NEVER be overridden
  }}
>

// ❌ WRONG - Tailwind classes can be overridden after refresh
<div className={`group absolute top-0 h-full ${color} rounded cursor-pointer`}>
```

**For Note Dots:**
```jsx
// ✅ CORRECT - Inline styles for colors and opacity
<div
  className="group absolute top-0 w-3 h-3 rounded-full border-2 border-white shadow-sm cursor-pointer transition-all"
  style={{ 
    left: `${notePosition}%`,
    transform: 'translateX(-50%) translateY(-5px)',
    backgroundColor: note.instanceVersion === 0 ? '#F59E0B' : '#8B5CF6',
    opacity: isVisible ? 1 : 0.5  // Inline opacity
  }}
>

// ❌ WRONG - Tailwind classes can conflict
<div className={`group absolute top-0 w-3 h-3 rounded-full border-2 border-white shadow-sm cursor-pointer transition-all ${
  note.instanceVersion === 0 ? 'bg-yellow-400' : 'bg-purple-400'
} ${isVisible ? 'opacity-100' : 'opacity-50'}`}>
```

**For All Interactive Elements:**
```jsx
// ✅ CORRECT - Inline styles for everything
<div
  className="absolute top-0 w-2 h-2 rounded-full border-2 border-white shadow-sm"
  style={{
    left: `${getCurrentTimelinePosition()}%`,
    transform: 'translateX(-50%) translateY(-3px)',
    backgroundColor: '#3B82F6'  // Inline style
  }}
/>

<div
  className="absolute -top-6 text-white text-xs px-2 py-0.5 rounded font-mono font-semibold z-30"
  style={{
    left: `${getCurrentTimelinePosition()}%`,
    transform: 'translateX(-50%)',
    backgroundColor: '#3B82F6'  // Inline style
  }}
>
```

### Key Points
1. **Use inline styles for ALL colors** - `backgroundColor`, `color`, `borderColor`
2. **Use inline styles for ALL opacity** - `opacity: 1` instead of `opacity-100`
3. **Remove ALL Tailwind color classes** - `bg-blue-400`, `text-white`, etc.
4. **Keep positioning classes** - `absolute`, `top-0`, `left-1/2`, etc. are fine
5. **Use hex colors** - `#3B82F6` instead of `bg-blue-400`

### When to Use This Pattern
- Timeline segments that must stay solid
- Hover popups that must stay solid
- Interactive elements that must maintain appearance
- Any element that becomes translucent after refresh
- Critical UI elements that users interact with

### Remember
Inline styles have the highest CSS specificity and will NEVER be overridden by external CSS. If something needs to stay solid after refresh, use inline styles for ALL color and opacity properties.

# DATABASE UPSERT ISSUES - ALWAYS CHECK UNIQUE CONSTRAINTS

## The Problem: Duplicate Entries from Upsert Operations

### Root Cause
When using Supabase's `.upsert()` method, if you don't specify the `onConflict` parameter, it defaults to using the primary key for conflict detection. This can cause duplicate entries when the unique constraint is on different columns.

### Real Example: Points History Tables
**Issue Encountered:**
- Multiple entries for the same area/subarea/goal on the same date
- Auto-save creating duplicate history records
- Inflated daily point totals

**Database Schema (from models):**
```typescript
// area_points_history
{
  name: 'area_points_history_unique_day',
  columns: ['area_id', 'date'],
  unique: true
}

// subarea_points_history  
{
  name: 'subarea_points_history_unique_day',
  columns: ['subarea_id', 'date'],
  unique: true
}

// goal_points_history
{
  name: 'goal_points_history_unique_day', 
  columns: ['goal_id', 'date'],
  unique: true
}
```

**Correct Upsert Implementation:**
```typescript
// ✅ CORRECT - Specify onConflict parameter
const { error: historyError } = await supabase
  .from('area_points_history')
  .upsert({
    user_id: user.id,
    area_id: area.id,
    date: dateStr,
    points: area.daily_points,
    target: area.target_points
  }, {
    onConflict: 'area_id,date'  // Match the unique constraint
  });

// ✅ CORRECT - For subareas
const { error: historyError } = await supabase
  .from('subarea_points_history')
  .upsert({
    user_id: user.id,
    area_id: subarea.area_id,
    subarea_id: subarea.id,
    date: dateStr,
    points: subarea.daily_points,
    target: subarea.target_points
  }, {
    onConflict: 'subarea_id,date'  // Match the unique constraint
  });

// ✅ CORRECT - For goals
const { error: historyError } = await supabase
  .from('goal_points_history')
  .upsert({
    user_id: user.id,
    area_id: goal.life_goal_subareas.area_id,
    subarea_id: goal.subarea_id,
    goal_id: goal.id,
    date: dateStr,
    points: goal.daily_points,
    target: goal.target_points
  }, {
    onConflict: 'goal_id,date'  // Match the unique constraint
  });
```

### Prevention Strategies

1. **Always Check Database Models First**
   - Look at the `indexes` array in the model definition
   - Find the unique constraint (usually named `*_unique_day`)
   - Use those exact columns in the `onConflict` parameter
   - Don't assume the primary key is the conflict target

2. **Common Unique Constraint Patterns**
   - Daily records: `(entity_id, date)`
   - User-specific records: `(user_id, entity_id)`
   - Time-based records: `(entity_id, timestamp)`
   - Composite keys: `(parent_id, child_id, date)`

3. **Debugging Upsert Issues**
   - Check for duplicate entries in the database
   - Verify the unique constraint exists and is correct
   - Ensure `onConflict` parameter matches the constraint
   - Test upsert with existing data to verify behavior

### Best Practices

1. **Always Specify onConflict**
   ```typescript
   // ✅ Always include onConflict
   .upsert(data, { onConflict: 'column1,column2' })
   
   // ❌ Don't rely on default behavior
   .upsert(data)
   ```

2. **Match Database Constraints**
   - Use the exact column names from the unique constraint
   - Order matters: `'area_id,date'` not `'date,area_id'`
   - Include all columns in the constraint

3. **Test Upsert Behavior**
   - Test with existing records
   - Verify updates work correctly
   - Check that duplicates are prevented
   - Monitor database for unexpected entries

### Remember
- Always check the database model's unique constraints before using upsert
- The `onConflict` parameter must match the actual unique constraint
- Don't assume the primary key is the conflict target
- Test upsert operations with existing data to verify behavior

# SUPABASE UPSERT ONCONFLICT SPECIFICATION ERRORS

## The Problem: "there is no unique or exclusion constraint matching the ON CONFLICT specification"

### Root Cause
When using Supabase's `.upsert()` method with `onConflict` parameter, the specified columns must exactly match an existing unique constraint in the database. If the constraint doesn't exist or the column names don't match, you'll get error code "42P10".

### Real Example: Points History Save Issue
**Error Encountered:**
```
Error code: "42P10"
Message: "there is no unique or exclusion constraint matching the ON CONFLICT specification"
```

**Common Causes:**
1. Database schema mismatch - columns don't exist in the table
2. Unique constraint was dropped or never created
3. Column names in `onConflict` don't match actual constraint
4. Migration not applied to database

### Solution: Use Insert + Update Pattern Instead

**Instead of problematic upsert:**
```typescript
// ❌ PROBLEMATIC - May fail with constraint errors
const { error } = await supabase
  .from('table_name')
  .upsert({
    column1: value1,
    column2: value2
  }, {
    onConflict: 'column1,column2'  // May not match actual constraint
  });
```

**Use insert + update pattern:**
```typescript
// ✅ RELIABLE - Works regardless of constraint issues
let { error } = await supabase
  .from('table_name')
  .insert({
    column1: value1,
    column2: value2
  });

// If insert fails due to duplicate, try update instead
if (error && error.code === '23505') { // unique_violation
  const { error: updateError } = await supabase
    .from('table_name')
    .update({
      // fields to update
    })
    .eq('column1', value1)
    .eq('column2', value2);
  
  error = updateError;
}
```

### When to Use This Pattern

1. **When you get "42P10" errors** with upsert operations
2. **When database schema is uncertain** or migrations may not be applied
3. **When working with tables** that have complex unique constraints
4. **For critical operations** that must work reliably

### Benefits

1. **More reliable** - doesn't depend on specific constraint names
2. **Easier to debug** - clear error handling for each step
3. **Works with any unique constraint** - doesn't need to know exact constraint name
4. **Graceful fallback** - handles both insert and update cases

### Error Code Reference

- **23505**: Unique constraint violation (expected when record exists)
- **42P10**: Invalid column reference in ON CONFLICT clause
- **42710**: Duplicate policy/constraint (when creating constraints)

### Remember
When upsert operations fail with constraint specification errors, use the insert + update pattern instead. It's more verbose but more reliable and doesn't depend on knowing the exact constraint names.

# CHARACTER XP CALCULATION - ON-THE-FLY VS STORED

## The Problem: Inflated Character Levels

### Root Cause
Character XP and levels are calculated **on-the-fly** from goal points history, not stored in a separate table. When duplicate entries exist in history tables, the XP calculation becomes inflated.

### How Character XP Works
1. **No stored character data**: The `characters` table doesn't exist in the current database
2. **On-the-fly calculation**: `getCharacterProgress()` calculates XP from goal points history every time
3. **Formula**: Total XP = Sum of goal points × 10
4. **Level calculation**: Uses the XP progression formula to determine level

### Real Example: Inflated Level Issue
**Problem**: Character showing level 7 when it should be level 4
**Cause**: Duplicate entries in `goal_points_history` table were inflating the total points
**Solution**: Clean up duplicate entries in history tables
**Result**: Refresh the page → correct level displays immediately

### Key Points
- **Character data is NOT stored** - it's calculated fresh each time
- **History tables are the source of truth** for XP calculation
- **Duplicate entries in history** = inflated XP = wrong character level
- **Page refresh** will show correct values after fixing history data
- **No need for character table migrations** - the calculation is real-time

### Debugging Character Level Issues
1. Check for duplicate entries in history tables
2. Verify `get_user_total_points` function is working correctly
3. Ensure goal points are being counted properly
4. Refresh the page to see updated calculations

### Remember
Character levels are calculated from goal points history, not stored in a separate table. If character levels seem wrong, check the history tables for duplicate entries or incorrect data.
